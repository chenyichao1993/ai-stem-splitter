const express = require('express');
const cors = require('cors');
const multer = require('multer');
const compression = require('compression');
const { v4: uuidv4 } = require('uuid');
const { supabase, BUCKET_NAME } = require('./config/supabase');
const { uploadToCloudinary, deleteFromCloudinary } = require('./utils/cloudinary');
const cloudinary = require('cloudinary').v2;
require('dotenv').config();

// é…ç½®Cloudinary
cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET
});

const app = express();
const PORT = process.env.PORT || 3001;

// å¯¼å…¥æ¸…ç†æœåŠ¡
const { scheduler } = require('../scripts/scheduler');

// ä¸­é—´ä»¶
app.use(compression()); // å¯ç”¨gzipå‹ç¼©
app.use(cors({
  origin: process.env.FRONTEND_URL || 'http://localhost:3000',
  credentials: true
}));
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// ç¼“å­˜ä¸­é—´ä»¶
const cacheMiddleware = (duration) => {
  return (req, res, next) => {
    res.set('Cache-Control', `public, max-age=${duration}, s-maxage=${duration}`);
    next();
  };
};

// å†…å­˜å­˜å‚¨
const storage = multer.memoryStorage();
const upload = multer({ 
  storage,
  limits: {
    fileSize: 50 * 1024 * 1024 // 50MB
  }
});

// å¥åº·æ£€æŸ¥
app.get('/health', cacheMiddleware(60), (req, res) => {
  res.json({ 
    status: 'OK', 
    timestamp: new Date().toISOString(),
    supabase: 'connected',
    version: process.env.npm_package_version || '1.0.0'
  });
});

// æ–‡ä»¶ä¸Šä¼ 
app.post('/api/upload', upload.single('audio'), async (req, res) => {
  try {
    console.log('ğŸ“ Upload request received');
    
    if (!req.file) {
      console.log('âŒ No file uploaded');
      return res.status(400).json({ success: false, error: 'No file uploaded' });
    }

    console.log('ğŸ“„ File details:', {
      originalname: req.file.originalname,
      size: req.file.size,
      mimetype: req.file.mimetype
    });

    const fileId = uuidv4();
    const fileExtension = req.file.originalname.split('.').pop()?.toLowerCase();
    const fileName = `${fileId}.${fileExtension}`;
    const filePath = `uploads/${fileId}/${fileName}`;
    
    // è®¾ç½®24å°æ—¶è¿‡æœŸæ—¶é—´
    const expiresAt = new Date();
    expiresAt.setHours(expiresAt.getHours() + 24);

    console.log('â˜ï¸ Starting Cloudinary upload...');
    
    // ä¸Šä¼ åˆ°Cloudinary
    const uploadResult = await uploadToCloudinary(req.file.buffer, {
      resource_type: 'auto',
      folder: 'stem-splitter/uploads',
      public_id: fileId
    });

    if (!uploadResult.success) {
      console.error('âŒ Cloudinary upload error:', uploadResult.error);
      return res.status(500).json({ success: false, error: 'Failed to upload file', details: uploadResult.error });
    }

    console.log('âœ… Cloudinary upload successful');
    const { data: cloudinaryData } = uploadResult;

    console.log('ğŸ’¾ Saving file info to database...');
    
    // ä¿å­˜æ–‡ä»¶ä¿¡æ¯åˆ°æ•°æ®åº“
    const { data: fileData, error: dbError } = await supabase
      .from('audio_files')
      .insert({
        id: fileId,
        user_id: null, // æš‚æ—¶ä¸ºnullï¼Œåç»­æ·»åŠ ç”¨æˆ·è®¤è¯
        original_name: req.file.originalname,
        file_name: fileName,
        file_size: req.file.size,
        mime_type: req.file.mimetype,
        storage_path: cloudinaryData.public_id,
        storage_url: cloudinaryData.secure_url,
        cloudinary_public_id: cloudinaryData.public_id,
        expires_at: expiresAt.toISOString()
      })
      .select()
      .single();

    if (dbError) {
      console.error('âŒ Database error:', dbError);
      return res.status(500).json({ success: false, error: 'Failed to save file info', details: dbError.message });
    }

    console.log('âœ… File info saved to database successfully');

    res.json({
      success: true,
      data: {
        fileId,
        fileName: req.file.originalname,
        fileSize: req.file.size,
        mimeType: req.file.mimetype,
        storageUrl: cloudinaryData.secure_url,
        publicId: cloudinaryData.public_id,
        expiresAt: expiresAt.toISOString()
      },
      message: 'File uploaded successfully to Cloudinary'
    });

  } catch (error) {
    console.error('âŒ Upload error:', error);
    console.error('âŒ Error stack:', error.stack);
    res.status(500).json({ 
      success: false, 
      error: 'Internal server error',
      details: error.message,
      stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
    });
  }
});

// ç®€å•æµ‹è¯•ç«¯ç‚¹
app.get('/api/test', (req, res) => {
  res.json({ success: true, message: 'Test endpoint working', timestamp: new Date().toISOString() });
});

// æ›´ç®€å•çš„æµ‹è¯•ç«¯ç‚¹
app.get('/test', (req, res) => {
  res.json({ message: 'Simple test working' });
});

// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
app.get('/api/check-file/:fileId', async (req, res) => {
  try {
    const { fileId } = req.params;
    
    const { data: audioFile, error: fileError } = await supabase
      .from('audio_files')
      .select('*')
      .eq('id', fileId)
      .single();
    
    if (fileError) {
      console.error('File check error:', fileError);
      return res.status(404).json({ success: false, error: 'File not found', details: fileError.message });
    }
    
    res.json({ success: true, data: audioFile });
  } catch (error) {
    console.error('Check file error:', error);
    res.status(500).json({ success: false, error: 'Internal server error' });
  }
});

// å¼€å§‹å¤„ç†
app.post('/api/process', async (req, res) => {
  try {
    const { fileId } = req.body;
    
    if (!fileId) {
      return res.status(400).json({ success: false, error: 'File ID is required' });
    }

    const jobId = uuidv4();

    // è·å–éŸ³é¢‘æ–‡ä»¶çš„è¿‡æœŸæ—¶é—´
    const { data: audioFile, error: fileError } = await supabase
      .from('audio_files')
      .select('expires_at')
      .eq('id', fileId)
      .single();
    
    if (fileError) {
      console.error('File fetch error:', fileError);
      return res.status(500).json({ success: false, error: 'Failed to fetch file info' });
    }

    // åˆ›å»ºå¤„ç†ä»»åŠ¡
    const { data: jobData, error: jobError } = await supabase
      .from('processing_jobs')
      .insert({
        id: jobId,
        user_id: null, // æš‚æ—¶ä¸ºnull
        audio_file_id: fileId,
        status: 'pending',
        progress: 0,
        estimated_time: 30,
        expires_at: audioFile.expires_at // ä½¿ç”¨ç›¸åŒçš„è¿‡æœŸæ—¶é—´
      })
      .select()
      .single();

    if (jobError) {
      console.error('Job creation error:', jobError);
      return res.status(500).json({ success: false, error: 'Failed to create processing job' });
    }

    // æ¨¡æ‹Ÿå¤„ç†ï¼ˆåç»­ä¼šé›†æˆçœŸå®AIå¼•æ“ï¼‰
    setTimeout(async () => {
      // æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
      await supabase
        .from('processing_jobs')
        .update({ status: 'processing' })
        .eq('id', jobId);

      // æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
      for (let progress = 10; progress <= 90; progress += 20) {
        await new Promise(resolve => setTimeout(resolve, 2000));
        await supabase
          .from('processing_jobs')
          .update({ progress })
          .eq('id', jobId);
      }

      // çœŸå®éŸ³é¢‘åˆ†ç¦»å¤„ç†
      const AudioSeparationService = require('./services/audio-separation');
      const separationService = new AudioSeparationService();
      
      // è·å–åŸå§‹éŸ³é¢‘æ–‡ä»¶
      const { data: audioFileData, error: audioError } = await supabase
        .from('audio_files')
        .select('storage_url, file_size')
        .eq('id', fileId)
        .single();
      
      if (audioError) {
        throw new Error('Failed to fetch audio file');
      }

      // ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
      const audioResponse = await fetch(audioFileData.storage_url);
      const audioBuffer = Buffer.from(await audioResponse.arrayBuffer());

      // æ‰§è¡ŒéŸ³é¢‘åˆ†ç¦»
      const separationResult = await separationService.separateAudio(audioBuffer, {
        service: 'lalalai' // å¯ä»¥é…ç½®ä½¿ç”¨å“ªä¸ªæœåŠ¡
      });

      const stemData = [];
      const stemTypes = Object.keys(separationResult);

      for (const stemType of stemTypes) {
        const stemId = uuidv4();
        const stemFileName = `${jobId}_${stemType}.mp3`;
        
        // è·å–åˆ†ç¦»åçš„éŸ³é¢‘æ•°æ®
        const stemUrl = separationResult[stemType];
        const stemResponse = await fetch(stemUrl);
        const stemBuffer = Buffer.from(await stemResponse.arrayBuffer());
        
        // ä¸Šä¼ åˆ°Cloudinary
        const stemUploadResult = await uploadToCloudinary(stemBuffer, {
          resource_type: 'auto',
          folder: 'stem-splitter/stems',
          public_id: `${jobId}_${stemType}`
        });

        if (stemUploadResult.success) {
          const { data: stemCloudinaryData } = stemUploadResult;

          // ä¿å­˜åˆ†ç¦»éŸ³è½¨ä¿¡æ¯
          await supabase
            .from('separated_stems')
            .insert({
              id: stemId,
              job_id: jobId,
              stem_type: stemType,
              file_name: stemFileName,
              file_size: stemBuffer.length,
              storage_path: stemCloudinaryData.public_id,
              storage_url: stemCloudinaryData.secure_url,
              cloudinary_public_id: stemCloudinaryData.public_id,
              expires_at: audioFile.expires_at // ä½¿ç”¨ç›¸åŒçš„è¿‡æœŸæ—¶é—´
            });

          stemData.push({
            [stemType]: stemCloudinaryData.secure_url
          });
        }
      }

      // æ›´æ–°ä»»åŠ¡å®Œæˆ
      await supabase
        .from('processing_jobs')
        .update({ 
          status: 'completed',
          progress: 100,
          completed_at: new Date().toISOString()
        })
        .eq('id', jobId);

    }, 1000);

    res.json({
      success: true,
      data: {
        jobId,
        status: 'pending',
        estimatedTime: 30
      },
      message: 'Processing started'
    });

  } catch (error) {
    console.error('Process error:', error);
    res.status(500).json({ success: false, error: 'Internal server error' });
  }
});

// è·å–å¤„ç†çŠ¶æ€
app.get('/api/process/:jobId', async (req, res) => {
  try {
    const { jobId } = req.params;
    
    const { data: job, error } = await supabase
      .from('processing_jobs')
      .select(`
        *,
        separated_stems (
          stem_type,
          storage_url,
          file_name
        )
      `)
      .eq('id', jobId)
      .single();

    if (error || !job) {
      return res.status(404).json({ success: false, error: 'Job not found' });
    }

    // æ ¼å¼åŒ–stemsæ•°æ®
    const stems = {};
    if (job.separated_stems) {
      job.separated_stems.forEach(stem => {
        stems[stem.stem_type] = stem.storage_url;
      });
    }

    res.json({
      success: true,
      data: {
        jobId: job.id,
        status: job.status,
        progress: job.progress,
        stems: Object.keys(stems).length > 0 ? stems : undefined,
        error: job.error_message
      }
    });

  } catch (error) {
    console.error('Status check error:', error);
    res.status(500).json({ success: false, error: 'Internal server error' });
  }
});

// ä¸‹è½½æ–‡ä»¶
app.get('/api/download/:jobId/:stemType', async (req, res) => {
  try {
    const { jobId, stemType } = req.params;
    
    const allowedStemTypes = ['vocals', 'drums', 'bass', 'guitar', 'piano'];
    if (!allowedStemTypes.includes(stemType)) {
      return res.status(400).json({ success: false, error: 'Invalid stem type' });
    }

    // è·å–åˆ†ç¦»éŸ³è½¨ä¿¡æ¯
    const { data: stem, error } = await supabase
      .from('separated_stems')
      .select('*')
      .eq('job_id', jobId)
      .eq('stem_type', stemType)
      .single();

    if (error || !stem) {
      return res.status(404).json({ success: false, error: 'Stem not found' });
    }

    // ä»Supabase Storageä¸‹è½½æ–‡ä»¶
    const { data: fileData, error: downloadError } = await supabase.storage
      .from(BUCKET_NAME)
      .download(stem.storage_path);

    if (downloadError) {
      console.error('Download error:', downloadError);
      return res.status(500).json({ success: false, error: 'Failed to download file' });
    }

    // è®¾ç½®å“åº”å¤´
    res.setHeader('Content-Disposition', `attachment; filename="${stem.file_name}"`);
    res.setHeader('Content-Type', 'audio/mpeg');
    res.setHeader('Content-Length', stem.file_size);

    // å‘é€æ–‡ä»¶
    const buffer = await fileData.arrayBuffer();
    res.send(Buffer.from(buffer));

  } catch (error) {
    console.error('Download error:', error);
    res.status(500).json({ success: false, error: 'Internal server error' });
  }
});

app.listen(PORT, () => {
  console.log(`ğŸš€ Real API server running on port ${PORT}`);
  console.log(`ğŸ“Š Health check: http://localhost:${PORT}/health`);
  console.log(`ğŸ”— API base URL: http://localhost:${PORT}/api`);
  console.log(`ğŸ—„ï¸ Supabase connected: ${supabase.supabaseUrl}`);
  
  // å¯åŠ¨è‡ªåŠ¨æ¸…ç†æœåŠ¡
  if (process.env.NODE_ENV === 'production') {
    console.log('ğŸ§¹ Starting automatic cleanup scheduler...');
    scheduler.start();
  } else {
    console.log('ğŸ”§ Development mode: Cleanup scheduler disabled');
  }
});
